{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reedhodges/pytorch-loop-integrals/blob/main/pytorch_loop_integrals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using PyTorch to classify loop integrals by the type of their divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should run this notebook in Google Colab; it is configured to download the necessary files from the Github repository.  Just make sure you run everything in the 'Preliminaries' section below before beginning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MHsMLuPvVtd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"integrand_data\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "    print(f\"[INFO] Directory {image_path} already exists, skipping download.\")\n",
        "else:\n",
        "    print(f\"[INFO] Creating {image_path} directory...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(data_path / \"integrand_data.zip\", \"wb\") as f:\n",
        "    url = \"https://github.com/reedhodges/pytorch-loop-integrals/raw/main/integrand_data.zip\"\n",
        "    response = requests.get(url)\n",
        "    print(f\"[INFO] Downloading zip from {url}...\")\n",
        "    f.write(response.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path / \"integrand_data.zip\", \"r\") as zip_ref:\n",
        "    print(f\"[INFO] Extracting zip to {image_path}...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "engine_path = \"engine.py\"\n",
        "utils_path = \"utils.py\"\n",
        "\n",
        "if not Path(engine_path).is_file():\n",
        "    print(f\"[INFO] Downloading {engine_path}...\")\n",
        "    with open(engine_path, \"wb\") as f:\n",
        "        url = \"https://raw.githubusercontent.com/reedhodges/pytorch-loop-integrals/main/engine.py\"\n",
        "        response = requests.get(url)\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(f\"[INFO] File {engine_path} already exists, skipping download.\")\n",
        "\n",
        "if not Path(utils_path).is_file():\n",
        "    print(f\"[INFO] Downloading {utils_path}...\")\n",
        "    with open(utils_path, \"wb\") as f:\n",
        "        url = \"https://raw.githubusercontent.com/reedhodges/pytorch-loop-integrals/main/utils.py\"\n",
        "        response = requests.get(url)\n",
        "        f.write(response.content)\n",
        "else:\n",
        "    print(f\"[INFO] File {utils_path} already exists, skipping download.\")\n",
        "\n",
        "print(f\"[INFO] All files downloaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set up data and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = image_path / \"train\"\n",
        "test_path = image_path / \"test\"\n",
        "\n",
        "image_path_list = list(data_path.glob(\"integrand_data/*/*/*.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import fix_error_with_weights_download\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "fix_error_with_weights_download()\n",
        "\n",
        "weights = EfficientNet_B0_Weights.DEFAULT\n",
        "model = efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "data_transform = weights.transforms()\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from engine import create_data_loaders, train\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "NUM_EPOCHS = 3\n",
        "path_to_data = image_path / \"data\"\n",
        "\n",
        "train_loader, test_loader, class_names, class_dict = create_data_loaders(path_to_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, train_transform=data_transform, test_transform=data_transform)\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280,\n",
        "              out_features=len(class_names)).to(device)\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        " \n",
        "train(device, model, train_loader, test_loader, loss_fn, optimizer, epochs=NUM_EPOCHS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNelMyb4UOclRPWI0D6bGvz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
